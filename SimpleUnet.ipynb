{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMEO+WD7TywJ2czJlbB1jE4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShikharGhimire/Diabetic-Retinopathy/blob/main/SimpleUnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jRqsk7eJaY4i"
      },
      "outputs": [],
      "source": [
        "### Segmenting retina blood vessels using UNET\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Accesing the google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7tnoReN5GUS",
        "outputId": "67b4b0d2-a540-4824-e8bf-f6f1dfc13345"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pandas as pd\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "import imageio\n",
        "from albumentations import HorizontalFlip, VerticalFlip, Rotate"
      ],
      "metadata": {
        "id": "L8lsNh0z1gmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__=='__main__':\n",
        "  np.random.seed(42)"
      ],
      "metadata": {
        "id": "qJ_D8ehl3M55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading the dataset\n",
        "def load_path(path):\n",
        "  train_x = sorted(glob(os.path.join(folder_path,'train','training','images','*.tif'))) #Image folder\n",
        "  train_y = sorted(glob(os.path.join(folder_path,'train','markup','*.gif'))) #Mask images y\n",
        "  #For testing folder\n",
        "  test_x = sorted(glob(os.path.join(folder_path,'test','images','*.tif'))) #Image folder\n",
        "  test_y = sorted(glob(os.path.join(folder_path,'test','mask','*.gif'))) #Mask images y\n",
        "  \n",
        "  return (train_x,train_y), (test_x,test_y)"
      ],
      "metadata": {
        "id": "6skdsz2V58PB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading the dataset\n",
        "folder_path = '/content/gdrive/My Drive/DBR/DRIVE'\n",
        "(train_x,train_y),(test_x,test_y) = load_path(folder_path)"
      ],
      "metadata": {
        "id": "hsjIqv7n4Je0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's check the length of the data\n",
        "print('Length of training data is {}-{}'.format(len(train_x),len(train_y)))\n",
        "print('Length of testing data is {}-{}'.format(len(test_x),len(test_y)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbxir_zf5yaQ",
        "outputId": "283f5d2c-80f4-423f-abf5-ed8078dc4675"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of training data is 20-20\n",
            "Length of testing data is 20-20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's check the dimension of the image\n",
        "training_images = []\n",
        "mask_images = []\n",
        "for i in train_x:\n",
        "  training_images.append(i)\n",
        "for j in train_y:\n",
        "  mask_images.append(j)"
      ],
      "metadata": {
        "id": "byuhIeqpBEZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = set([cv2.imread(x).shape for x in training_images])\n",
        "print('All the image sizes are',image_size)\n",
        "\n",
        "#All the image size is that of 584x563 with 3 channels\n",
        "\n",
        "#Let's look at mask dimensions\n",
        "mask_size = set([imageio.mimread(x)[0].shape for x in mask_images])\n",
        "print('All the mask sizes are',mask_size)\n",
        "\n",
        "#All the mask size is that of 584x565"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBcPfX-mCjfA",
        "outputId": "f9a8fc27-96ad-4a2c-e4b1-076c6441e95c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All the image sizes are {(584, 565, 3)}\n",
            "All the mask sizes are {(584, 565)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #Data Augmentation for the retinal eye images\n",
        "# def create_dir(path):\n",
        "#   if not os.path.exists(path):\n",
        "#     os.makedirs(path)\n",
        "\n",
        "# #Creating directories to save the augmented data\n",
        "# create_dir('/content/gdrive/My Drive/DBR/DRIVE/aug_train/images')\n",
        "# create_dir('/content/gdrive/My Drive/DBR/DRIVE/aug_train/mask')\n",
        "# create_dir('/content/gdrive/My Drive/DBR/DRIVE/aug_test/image')\n",
        "# create_dir('/content/gdrive/My Drive/DBR/DRIVE/aug_test/mask')"
      ],
      "metadata": {
        "id": "Tr2aJqbg6yF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's create some augmented image\n",
        "def augmented_data(images,masks,save_path,augment = True):\n",
        "  size = (560,560)\n",
        "  for idx, (x,y) in tqdm(enumerate(zip(images,masks)),total = len(images)):\n",
        "    image_name = x.split('/')[-1].split('.')[0] #Extracting the name of the file\n",
        "    #Reading the image and the mask\n",
        "    x = cv2.imread(x,cv2.IMREAD_COLOR)\n",
        "    y = imageio.mimread(y)[0]\n",
        "    \n",
        "    if augment == True: #If we want to do the augmentation\n",
        "      #Horizontal flipping\n",
        "      aug = HorizontalFlip(p=1.0)\n",
        "      augmented = aug(image = x, mask = y)\n",
        "      x1 = augmented['image']\n",
        "      y1 = augmented['mask']\n",
        "\n",
        "      #Vertical Flipping\n",
        "      aug = VerticalFlip(p = 1.0)\n",
        "      augmented = aug(image=x,mask = y)\n",
        "      x2 = augmented['image']\n",
        "      y2 = augmented['mask']\n",
        "\n",
        "      #Rotating\n",
        "      aug = Rotate(limit = 45, p = 1.0)\n",
        "      augmented = aug(image=x,mask = y)\n",
        "      x3 = augmented['image']\n",
        "      y3 = augmented['mask']\n",
        "\n",
        "      X = [x,x1,x2,x3]\n",
        "      Y = [y,y1,y2,y3]\n",
        "\n",
        "    else:\n",
        "      X = [x]\n",
        "      Y = [y]\n",
        "\n",
        "    index = 0\n",
        "    for i,m in zip(X,Y):\n",
        "      i = cv2.resize(i,size)\n",
        "      m = cv2.resize(m,size)\n",
        "\n",
        "      #Creating temporary name to store all the augmented data\n",
        "      tmp_image_name = f\"{image_name}_{index}.png\"\n",
        "      tmp_mask_name = f\"{image_name}_{index}.png\"\n",
        "\n",
        "      image_path = os.path.join(save_path,\"images\",tmp_image_name)\n",
        "      mask_path =  os.path.join(save_path,\"mask\",tmp_mask_name)\n",
        "\n",
        "      cv2.imwrite(image_path,i)\n",
        "      cv2.imwrite(mask_path,m)\n",
        "\n",
        "      index = index+1\n"
      ],
      "metadata": {
        "id": "bLVwDZjn_5gQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "augmented_data(train_x, train_y,'/content/gdrive/My Drive/DBR/DRIVE/aug_train/', augment = True) #For training data\n",
        "augmented_data(train_x,train_y,'/content/gdrive/My Drive/DBR/DRIVE/aug_test/',augment = False) #For testing data as we do not need to do any augmentation on it we put augment as false"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_c8IDQjSEKR6",
        "outputId": "ededc2ca-f260-4355-ed5d-f62ee6c9ddd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.24it/s]\n",
            "100%|██████████| 20/20 [00:00<00:00, 26.33it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pytorch Unet architecture\n"
      ],
      "metadata": {
        "id": "M2HuPi3V1Ecp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "bVo-8F8Q1I3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class conv_block(nn.Module):\n",
        "  def __init__(self,in_c,out_c):\n",
        "    super().__init__()\n",
        "    #First convolution layer\n",
        "    self.conv1 = nn.Conv2d(in_c, out_c, kernel_size = 3, padding =1)\n",
        "\n",
        "  def forward(self,inputs):\n",
        "    x = self.conv1(inputs)\n",
        "    print(x)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  x = torch.randn((2,32,128,128)) #batch size,number_of_channels,height,width \n",
        "  b = conv_block(32,64) #Calling the conv block class\n",
        "  b(x)\n"
      ],
      "metadata": {
        "id": "kLX2bbLX1P9W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}