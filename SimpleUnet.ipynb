{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPKwKVQofrY65E1pdQbk0fr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShikharGhimire/Diabetic-Retinopathy/blob/main/SimpleUnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jRqsk7eJaY4i"
      },
      "outputs": [],
      "source": [
        "### Segmenting retina blood vessels using UNET"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Accesing the google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7tnoReN5GUS",
        "outputId": "d3233774-11d4-4b2a-9ce8-31683527f4f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pandas as pd\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "import imageio\n",
        "from albumentations import HorizontalFlip, VerticalFlip, Rotate\n",
        "import time\n",
        "import random\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "L8lsNh0z1gmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading the dataset\n",
        "def load_path(path):\n",
        "  train_x = sorted(glob(os.path.join(folder_path,'train','training','images','*.tif'))) #Image folder\n",
        "  train_y = sorted(glob(os.path.join(folder_path,'train','markup','*.gif'))) #Mask images y\n",
        "  #For testing folder\n",
        "  test_x = sorted(glob(os.path.join(folder_path,'test','images','*.tif'))) #Image folder\n",
        "  test_y = sorted(glob(os.path.join(folder_path,'test','mask','*.gif'))) #Mask images y\n",
        "  \n",
        "  return (train_x,train_y), (test_x,test_y)"
      ],
      "metadata": {
        "id": "6skdsz2V58PB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading the dataset\n",
        "folder_path = '/content/gdrive/My Drive/DBR/DRIVE'\n",
        "(train_x,train_y),(test_x,test_y) = load_path(folder_path)"
      ],
      "metadata": {
        "id": "hsjIqv7n4Je0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's check the length of the data\n",
        "print('Length of training data is {}-{}'.format(len(train_x),len(train_y)))\n",
        "print('Length of testing data is {}-{}'.format(len(test_x),len(test_y)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbxir_zf5yaQ",
        "outputId": "354c90bd-a8dd-498e-b935-a50190cd8484"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of training data is 20-20\n",
            "Length of testing data is 20-20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's check the dimension of the image\n",
        "training_images = []\n",
        "mask_images = []\n",
        "for i in train_x:\n",
        "  training_images.append(i)\n",
        "for j in train_y:\n",
        "  mask_images.append(j)"
      ],
      "metadata": {
        "id": "byuhIeqpBEZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = set([cv2.imread(x).shape for x in training_images])\n",
        "print('All the image sizes are',image_size)\n",
        "\n",
        "#All the image size is that of 584x563 with 3 channels\n",
        "\n",
        "#Let's look at mask dimensions\n",
        "mask_size = set([imageio.mimread(x)[0].shape for x in mask_images])\n",
        "print('All the mask sizes are',mask_size)\n",
        "\n",
        "#All the mask size is that of 584x565"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBcPfX-mCjfA",
        "outputId": "a86b199d-ca8b-4000-a36e-8512a4cd187e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All the image sizes are {(584, 565, 3)}\n",
            "All the mask sizes are {(584, 565)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #Data Augmentation for the retinal eye images\n",
        "# def create_dir(path):\n",
        "#   if not os.path.exists(path):\n",
        "#     os.makedirs(path)\n",
        "\n",
        "# #Creating directories to save the augmented data\n",
        "# create_dir('/content/gdrive/My Drive/DBR/DRIVE/aug_train/images')\n",
        "# create_dir('/content/gdrive/My Drive/DBR/DRIVE/aug_train/mask')\n",
        "# create_dir('/content/gdrive/My Drive/DBR/DRIVE/aug_test/images')\n",
        "# create_dir('/content/gdrive/My Drive/DBR/DRIVE/aug_test/mask')"
      ],
      "metadata": {
        "id": "Tr2aJqbg6yF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's create some augmented image\n",
        "def augmented_data(images,masks,save_path,augment = True):\n",
        "  size = (560,560)\n",
        "  for idx, (x,y) in tqdm(enumerate(zip(images,masks)),total = len(images)):\n",
        "    image_name = x.split('/')[-1].split('.')[0] #Extracting the name of the file\n",
        "    #Reading the image and the mask\n",
        "    x = cv2.imread(x,cv2.IMREAD_COLOR)\n",
        "    y = imageio.mimread(y)[0]\n",
        "    \n",
        "    if augment == True: #If we want to do the augmentation\n",
        "      #Horizontal flipping\n",
        "      aug = HorizontalFlip(p=1.0)\n",
        "      augmented = aug(image = x, mask = y)\n",
        "      x1 = augmented['image']\n",
        "      y1 = augmented['mask']\n",
        "\n",
        "      #Vertical Flipping\n",
        "      aug = VerticalFlip(p = 1.0)\n",
        "      augmented = aug(image=x,mask = y)\n",
        "      x2 = augmented['image']\n",
        "      y2 = augmented['mask']\n",
        "\n",
        "      #Rotating\n",
        "      aug = Rotate(limit = 45, p = 1.0)\n",
        "      augmented = aug(image=x,mask = y)\n",
        "      x3 = augmented['image']\n",
        "      y3 = augmented['mask']\n",
        "\n",
        "      X = [x,x1,x2,x3]\n",
        "      Y = [y,y1,y2,y3]\n",
        "\n",
        "    else:\n",
        "      X = [x]\n",
        "      Y = [y]\n",
        "\n",
        "    index = 0\n",
        "    for i,m in zip(X,Y):\n",
        "      i = cv2.resize(i,size)\n",
        "      m = cv2.resize(m,size)\n",
        "\n",
        "      #Creating temporary name to store all the augmented data\n",
        "      tmp_image_name = f\"{image_name}_{index}.png\"\n",
        "      tmp_mask_name = f\"{image_name}_{index}.png\"\n",
        "\n",
        "      image_path = os.path.join(save_path,\"images\",tmp_image_name)\n",
        "      mask_path =  os.path.join(save_path,\"mask\",tmp_mask_name)\n",
        "\n",
        "      cv2.imwrite(image_path,i)\n",
        "      cv2.imwrite(mask_path,m)\n",
        "\n",
        "      index = index+1\n"
      ],
      "metadata": {
        "id": "bLVwDZjn_5gQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# augmented_data(train_x, train_y,'/content/gdrive/My Drive/DBR/DRIVE/aug_train/', augment = True) #For training data\n",
        "# augmented_data(train_x,train_y,'/content/gdrive/My Drive/DBR/DRIVE/aug_test/',augment = False) #For testing data as we do not need to do any augmentation on it we put augment as false"
      ],
      "metadata": {
        "id": "_c8IDQjSEKR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pytorch Unet architecture\n"
      ],
      "metadata": {
        "id": "M2HuPi3V1Ecp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class conv_block(nn.Module):\n",
        "  def __init__(self,in_c,out_c):\n",
        "    super().__init__()\n",
        "    #First convolution layer\n",
        "    self.conv1 = nn.Conv2d(in_c, out_c, kernel_size = 3, padding =1)\n",
        "    self.bn1 = nn.BatchNorm2d(out_c)\n",
        "\n",
        "    self.conv2 = nn.Conv2d(out_c, out_c, kernel_size = 3, padding =1)\n",
        "    self.bn2 = nn.BatchNorm2d(out_c)\n",
        "\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "  def forward(self,inputs):\n",
        "    x = self.conv1(inputs)\n",
        "    x = self.bn1(x)\n",
        "    x = self.relu(x)\n",
        "\n",
        "    x = self.conv2(x)\n",
        "    x = self.bn2(x)\n",
        "    x = self.relu(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "kLX2bbLX1P9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Using encoder block\n",
        "class encoder_block(nn.Module):\n",
        "  def __init__(self,in_c,out_c):\n",
        "    super().__init__()\n",
        "\n",
        "    self.conv = conv_block(in_c,out_c)\n",
        "    self.pool = nn.MaxPool2d((2,2))\n",
        "\n",
        "  def forward(self,inputs):\n",
        "    x = self.conv(inputs)\n",
        "    p = self.pool(x)\n",
        "    \n",
        "    return x,p"
      ],
      "metadata": {
        "id": "7tZJ2EJuOKnf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DECODER block\n",
        "class decoder_block(nn.Module):\n",
        "  def __init__(self,in_c,out_c):\n",
        "    super().__init__()\n",
        "    self.up = nn.ConvTranspose2d(in_c,out_c,kernel_size = 2,stride = 2,padding = 0)\n",
        "    self.conv = conv_block(out_c+out_c,out_c)\n",
        "\n",
        "  def forward(self,inputs,skip):\n",
        "    x = self.up(inputs)\n",
        "    x = torch.cat([x,skip], axis = 1)\n",
        "    x = self.conv(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "D5AtioRTOLy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class build_unet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    #Making some encoder layers\n",
        "    self.e1 = encoder_block(3,64) #RGB image and number of output channel\n",
        "    self.e2 = encoder_block(64,128)\n",
        "\n",
        "    self.e3 = encoder_block(128,256)\n",
        "    self.e4 = encoder_block(256,512)\n",
        "\n",
        "    #Creating the bottleneck in UNET architecture\n",
        "    self.b = conv_block(512,1024)\n",
        "\n",
        "    #Making some decoder layers\n",
        "    self.d1 = decoder_block(1024,512)\n",
        "    self.d2 = decoder_block(512,256)\n",
        "    self.d3 = decoder_block(256,128)\n",
        "    self.d4 = decoder_block(128,64)\n",
        "\n",
        "    #Classifier\n",
        "    self.outputs = nn.Conv2d(64, 1, kernel_size = 1, padding = 0) #Classifier to generate the segmentation mask\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    #Encoder\n",
        "    s1,p1 = self.e1(inputs)\n",
        "    s2,p2 = self.e2(p1)\n",
        "    s3,p3 = self.e3(p2)\n",
        "    s4,p4 = self.e4(p3)\n",
        "\n",
        "    #Bottleneck\n",
        "    b = self.b(p4)\n",
        "\n",
        "    #Decoders class\n",
        "    d1 = self.d1(b,s4)\n",
        "    d2 = self.d2(d1,s3)\n",
        "    d3 = self.d3(d2,s2)\n",
        "    d4 = self.d4(d3,s1)\n",
        "\n",
        "    outputs = self.outputs(d4)\n",
        "\n",
        "    return outputs\n",
        "\n",
        "    # print(s1.shape,s2.shape,s3.shape,s4.shape)\n",
        "    # print(b.shape)\n"
      ],
      "metadata": {
        "id": "tl-wf_MA33MB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Loss function\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self, weight=None, size_average=True):\n",
        "        super(DiceLoss, self).__init__()\n",
        "\n",
        "    def forward(self, inputs, targets, smooth=1):\n",
        "\n",
        "        \n",
        "        inputs = torch.sigmoid(inputs)\n",
        "\n",
        "        #flatten label and prediction tensors\n",
        "        inputs = inputs.view(-1)\n",
        "        targets = targets.view(-1)\n",
        "\n",
        "        intersection = (inputs * targets).sum()\n",
        "        dice = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)\n",
        "\n",
        "        return 1 - dice\n",
        "\n",
        "class DiceBCELoss(nn.Module):\n",
        "    def __init__(self, weight=None, size_average=True):\n",
        "        super(DiceBCELoss, self).__init__()\n",
        "\n",
        "    def forward(self, inputs, targets, smooth=1):\n",
        "\n",
        "        \n",
        "        inputs = torch.sigmoid(inputs)\n",
        "\n",
        "        #flatten label and prediction tensors\n",
        "        inputs = inputs.view(-1)\n",
        "        targets = targets.view(-1)\n",
        "\n",
        "        intersection = (inputs * targets).sum()\n",
        "        dice_loss = 1 - (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)\n",
        "        BCE = F.binary_cross_entropy(inputs, targets, reduction='mean')\n",
        "        Dice_BCE = BCE + dice_loss\n",
        "\n",
        "        return Dice_BCE"
      ],
      "metadata": {
        "id": "WwoAU6hro4_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ##Building a UNET structure\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#   x = torch.randn((2,3,512,512)) #batch size,number_of_channels,height,width \n",
        "#   b = build_unet()\n",
        "#   y = b(x)\n",
        "#   print(y.shape)"
      ],
      "metadata": {
        "id": "6WrVdylkOOBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating the data pipelines\n",
        "\n",
        "class DriveDataset(Dataset):\n",
        "    def __init__(self, images_path, masks_path):\n",
        "\n",
        "        self.images_path = images_path\n",
        "        self.masks_path = masks_path\n",
        "        self.n_samples = len(images_path) #Checking the number of images\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\" Reading image \"\"\"\n",
        "        image = cv2.imread(self.images_path[index], cv2.IMREAD_COLOR)\n",
        "        image = image/255.0 \n",
        "        image = np.transpose(image, (2, 0, 1)) \n",
        "        image = image.astype(np.float32)\n",
        "        image = torch.from_numpy(image) #Converting it into numpy tensors\n",
        "\n",
        "        \"\"\" Reading mask \"\"\"\n",
        "        mask = cv2.imread(self.masks_path[index], cv2.IMREAD_GRAYSCALE)\n",
        "        mask = mask/255.0   \n",
        "        mask = np.expand_dims(mask, axis=0) \n",
        "        mask = mask.astype(np.float32)\n",
        "        mask = torch.from_numpy(mask)\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "    def __len__(self): #To return the number of samples\n",
        "        return self.n_samples"
      ],
      "metadata": {
        "id": "IKv03l0cyDWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__=='__main__':\n",
        "  np.random.seed(42)\n",
        "\n",
        "  #Loading the dataset\n",
        "  train_X = sorted(glob('/content/gdrive/My Drive/DBR/DRIVE/aug_train/images/*'))[:20]\n",
        "  train_y = sorted(glob('/content/gdrive/My Drive/DBR/DRIVE/aug_train/mask/*'))[:20]\n",
        "\n",
        "  #Validation data\n",
        "  valid_X = sorted(glob('/content/gdrive/My Drive/DBR/DRIVE/aug_test/images/*'))\n",
        "  valid_Y = sorted(glob('/content/gdrive/My Drive/DBR/DRIVE/aug_test/mask/*'))"
      ],
      "metadata": {
        "id": "j43i0vFwym0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Length of training data is {} and length of validation data is {}'.format(len(train_X),len(valid_X)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ia1lVKB-0XH8",
        "outputId": "ef235441-bd55-43a4-92f7-3232537198cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of training data is 20 and length of validation data is 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Using hyper parameters\n",
        "H = 565\n",
        "W = 565\n",
        "size = (H,W)\n",
        "batch_size = 2\n",
        "num_epochs = 50\n",
        "lr = 1e-4\n",
        "checkpoint_path = '/content/gdrive/My Drive/DBR/DRIVE'\n",
        "\n",
        "\n",
        "#Using Dataset for training\n",
        "\n",
        "train_image = DriveDataset(train_X,train_y)\n",
        "test_image = DriveDataset(train_y,valid_Y)\n",
        "\n",
        "#Using loader\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "#Using train data loader\n",
        "train_loader = DataLoader(\n",
        "    dataset = train_image,\n",
        "    batch_size = batch_size,\n",
        "    shuffle = True,\n",
        "    num_workers = 2 #Check what this is about\n",
        "    )\n",
        "\n",
        "#Using test data loader\n",
        "\n",
        "valid_loader = DataLoader(\n",
        "    dataset = test_image,\n",
        "    batch_size = batch_size,\n",
        "    shuffle = True,\n",
        "    num_workers = 2 #Check what this is about\n",
        "    )"
      ],
      "metadata": {
        "id": "S2rTIJtX1cYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Compiling the UNET\n",
        "model = build_unet()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr = lr)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience = 5,verbose = True)\n",
        "loss_fn = DiceBCELoss()"
      ],
      "metadata": {
        "id": "LdSl3n3_m6aU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a training function\n",
        "def train(model,loader,optimizer,loss_fn):\n",
        "  epoch_loss = 0.0\n",
        "  model.train()\n",
        "  for x,y in loader:\n",
        "    x.dtype == np.float32\n",
        "    y.dtype == np.float32 \n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    y_pred = model(x)\n",
        "    loss = loss_fn(y_pred,y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    epoch_loss = epoch_loss+loss.item() #For training\n",
        "\n",
        "  epoch_loss = epoch_loss/len(loader)\n",
        "  return epoch_loss\n",
        "\n",
        "def evaluate(model,loader,loss_fn):\n",
        "  epoch_loss = 0.0\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for x,y in loader:\n",
        "      x.dtype == np.float32\n",
        "      y.dtype == np.float32\n",
        "      y_pred = model(x) \n",
        "      loss = loss_fn(y_pred,y)\n",
        "      epoch_loss = epoch_loss+loss.item()\n",
        "\n",
        "    epoch_loss = epoch_loss/len(loader) #For evaluation\n",
        "  return epoch_loss\n",
        "\n",
        "\n",
        "#Training the model\n",
        "for epoch in range(num_epochs):\n",
        "  start_time = time.time()\n",
        "  train_loss = train(model,train_loader,optimizer,loss_fn)\n",
        "  valid_loss = evaluate(model,valid_loader,loss_fn)\n",
        "\n",
        "  end_time = time.time()\n",
        "\n",
        "  print('Train loss: {}'.format(train_loss))\n",
        "  print('Valid loss : {}'.format(valid_loss))"
      ],
      "metadata": {
        "id": "2o-OVxbpqf7U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}